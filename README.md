# Intelligent Agent for Automated Data Collection & Processing

[![Python 3.9+](https://img.shields.io/badge/python-3.9+-blue.svg)](https://www.python.org/downloads/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

An AI-powered agent system for autonomous data collection, processing, and storage using modern AI/ML tools and frameworks.

## ğŸš€ Quick Start

### Option 1: Run Demo (No API Keys Required)

```bash
# Clone and navigate to project
cd intelligent_agent_project

# Run the demo with mock data
python demo.py
```

### Option 2: Full Setup

```bash
# 1. Run setup script
python setup.py

# 2. Install dependencies
pip install -r requirements.txt
python -m spacy download en_core_web_sm

# 3. Configure environment
copy .env.example .env
# Edit .env with your API keys

# 4. Run tests
pytest tests/ -v

# 5. Run the agent
python test_run.py
```

## âœ¨ Features

- ğŸ¤– **Autonomous Data Collection** - Scrapes websites and calls APIs automatically
- ğŸ”„ **Self-Healing Scrapers** - Adapts to website layout changes
- âœ… **Data Quality Validation** - Validates data against configurable rules
- ğŸ” **Anomaly Detection** - Uses ML to detect unusual patterns in data
- ğŸ‘¥ **Human-in-the-Loop** - Queues problematic data for review
- ğŸ“Š **Quality Metrics** - Tracks completeness, uniqueness, and consistency
- ï¿½ **Incremental Processing** - Only processes changed data
- ğŸ¤ **Multi-Agent System** - Specialized agents collaborate effectively
- â˜ï¸ **Cloud-Ready** - Deployable to Azure Functions or AWS Lambda
- ğŸ“ˆ **Rate Limiting** - Intelligent request throttling

## ï¿½ Project Structure

```
intelligent_agent_project/
â”œâ”€â”€ agents/                    # Agent implementations
â”‚   â”œâ”€â”€ core_agent.py         # Main agent orchestration
â”‚   â””â”€â”€ specialized/          # Specialized agent modules
â”‚       â”œâ”€â”€ collector_agent.py
â”‚       â”œâ”€â”€ processor_agent.py
â”‚       â””â”€â”€ storage_agent.py
â”œâ”€â”€ modules/                   # Core functionality modules
â”‚   â”œâ”€â”€ collector/            # Data collection
â”‚   â”‚   â”œâ”€â”€ web_scraper.py   # Self-healing web scraper
â”‚   â”‚   â””â”€â”€ api_client.py    # Rate-limited API client
â”‚   â”œâ”€â”€ processor/            # Data processing
â”‚   â”‚   â”œâ”€â”€ data_cleaner.py  # Data cleaning & transformation
â”‚   â”‚   â””â”€â”€ nlp_extractor.py # NLP entity extraction
â”‚   â””â”€â”€ storage/              # Data persistence
â”‚       â””â”€â”€ database_manager.py
â”œâ”€â”€ config/                   # Configuration files
â”‚   â””â”€â”€ settings.py          # Project settings
â”œâ”€â”€ tests/                    # Test suite
â”‚   â”œâ”€â”€ test_agents.py
â”‚   â”œâ”€â”€ test_collector.py
â”‚   â”œâ”€â”€ test_processor.py
â”‚   â””â”€â”€ test_storage.py
â”œâ”€â”€ docs/                     # Documentation
â”‚   â””â”€â”€ project_guide.md     # Complete guide
â”œâ”€â”€ logs/                     # Application logs
â”œâ”€â”€ data/                     # Data storage
â”‚   â”œâ”€â”€ raw/                 # Raw collected data
â”‚   â””â”€â”€ processed/           # Processed data
â”œâ”€â”€ main.py                   # Main application entry
â”œâ”€â”€ demo.py                   # Demo with mock data
â”œâ”€â”€ test_run.py              # Test runner
â”œâ”€â”€ setup.py                 # Setup script
â”œâ”€â”€ requirements.txt         # Python dependencies
â””â”€â”€ .env.example            # Environment template
```

## ğŸ¯ Architecture

The project is organized into several key modules:

- **Agents**: Core agent implementation using LangChain, CrewAI, and AutoGen
- **Modules**:
  - Collector: Web scraping and API integration
  - Processor: Data cleaning and NLP processing
  - Storage: Database management and persistence
- **Config**: Configuration management and settings
- **Tests**: Comprehensive test suite

### Data Flow

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Collector  â”‚ --> â”‚  Processor   â”‚ --> â”‚   Storage   â”‚
â”‚    Agent    â”‚     â”‚    Agent     â”‚     â”‚    Agent    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
      â”‚                    â”‚                     â”‚
      â†“                    â†“                     â†“
 Web Scraping        Data Cleaning         Database
 API Calls           Validation            Review Queue
 Rate Limiting       Anomaly Detection     Deduplication
```

## ğŸ“š Prerequisites

- Python 3.9+
- OpenAI API key (for full functionality)
- SQLite (default) or other SQL database
- Required Python packages (see `requirements.txt`)

## ğŸ”§ Configuration

### Environment Variables (.env)

```env
# Required
OPENAI_API_KEY=your_openai_api_key_here
DATABASE_URL=sqlite:///./agent_data.db

# Optional
NOTIFICATION_EMAIL=alerts@example.com

# Cloud Deployment (Optional)
AZURE_FUNCTION_APP_NAME=intelligent-agent
AWS_LAMBDA_FUNCTION_NAME=intelligent-agent
```

### Validation Rules

Edit `config/settings.py` to customize validation:

```python
PROCESSOR_CONFIG = {
    "validation_rules": {
        "email": [{
            "type": "format",
            "pattern": r"^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}$"
        }],
        "price": [{
            "type": "range",
            "min": 0,
            "max": 1000000
        }]
    }
}
```

## ğŸ’¡ Usage Examples

### Basic Usage

```python
import asyncio
from main import IntelligentAgent

async def main():
    agent = IntelligentAgent()
    
    sources = [
        {
            "type": "website",
            "url": "https://example.com/data"
        },
        {
            "type": "api",
            "endpoint": "https://api.example.com/data",
            "params": {"key": "value"}
        }
    ]
    
    results = await agent.run(sources, parallel=True)
    print(results)

if __name__ == "__main__":
    asyncio.run(main())
```

### Review Workflow

```python
# Get pending reviews
reviews = agent.get_review_queue()

# Review and approve/reject
for review in reviews:
    data = agent.get_data_by_id(review['id'])
    if is_valid(data):
        agent.approve_review(review['id'], reviewer="admin")
    else:
        agent.reject_review(review['id'], reviewer="admin", reason="Invalid")
```

## ğŸ§ª Testing

```bash
# Run all tests
pytest tests/

# Run with coverage
pytest tests/ --cov=.

# Run specific test
pytest tests/test_agents.py -v
```

## ğŸš¢ Cloud Deployment

### Azure Functions

```bash
az login
az functionapp create --resource-group <group> \
  --consumption-plan-location eastus \
  --runtime python --runtime-version 3.9 \
  --name <app-name>
func azure functionapp publish <app-name>
```

### AWS Lambda

```bash
aws configure
pip install --target ./package -r requirements.txt
cd package && zip -r ../deployment.zip . && cd ..
zip -g deployment.zip main.py
aws lambda create-function --function-name intelligent-agent \
  --runtime python3.9 --handler main.lambda_handler \
  --zip-file fileb://deployment.zip
```

## ğŸ“– Documentation

- [Complete Project Guide](docs/project_guide.md) - Comprehensive documentation
- [API Reference](docs/project_guide.md#api-reference) - Detailed API docs
- [Deployment Guide](docs/project_guide.md#deployment) - Cloud deployment instructions

## ğŸ› Troubleshooting

### Common Issues

1. **Import Errors**: Run `pip install -r requirements.txt`
2. **API Errors**: Check your `.env` file and API key
3. **Database Errors**: Ensure write permissions for database directory
4. **Rate Limiting**: Adjust rate limits in `config/settings.py`

See the [Troubleshooting Guide](docs/project_guide.md#troubleshooting) for more help.

## ğŸ¤ Contributing

1. Fork the repository
2. Create your feature branch (`git checkout -b feature/AmazingFeature`)
3. Commit your changes (`git commit -m 'Add some AmazingFeature'`)
4. Push to the branch (`git push origin feature/AmazingFeature`)
5. Open a Pull Request

## ğŸ“ License

This project is licensed under the MIT License - see the LICENSE file for details.

## ğŸ™ Acknowledgments

- OpenAI for GPT models
- LangChain community
- CrewAI and AutoGen frameworks
- spaCy for NLP capabilities

## ğŸ“§ Support

For issues and questions:
- Open an issue on GitHub
- Check the [documentation](docs/project_guide.md)
- Review logs in `logs/agent.log`

---

**Built with â¤ï¸ for autonomous data processing**
